from pathlib import Path
import google.generativeai as genai
import os
import json
from PIL import Image
import requests
from io import BytesIO
from pydub import AudioSegment
import speech_recognition as sr
import pytesseract
from dotenv import load_dotenv
import django

# Thi·∫øt l·∫≠p bi·∫øn m√¥i tr∆∞·ªùng tr∆∞·ªõc khi import models
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'EnglishApp.settings')  # Thay b·∫±ng t√™n project th·ª±c c·ªßa b·∫°n
django.setup()

from EStudyApp.models import History

pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# ‚úÖ Th√™m ffmpeg v√†o PATH ƒë·ªÉ subprocess t√¨m th·∫•y
os.environ["PATH"] += os.pathsep + r"D:\tools-upgraders\ffmpeg-2025-04-14-git-3b2a9410ef-essentials_build\bin"

# üîß ƒê·∫∑t l·∫°i converter v√† ffprobe cho Pydub
AudioSegment.converter = r"D:\tools-upgraders\ffmpeg-2025-04-14-git-3b2a9410ef-essentials_build\bin\ffmpeg.exe"
AudioSegment.ffprobe = r"D:\tools-upgraders\ffmpeg-2025-04-14-git-3b2a9410ef-essentials_build\bin\ffprobe.exe"

print("‚úÖ Ki·ªÉm tra FFmpeg:", os.path.isfile(AudioSegment.converter))
print("‚úÖ Ki·ªÉm tra FFprobe:", os.path.isfile(AudioSegment.ffprobe))
# Load API Key t·ª´ file .env
env_path = Path(__file__).parent / '.env'
load_dotenv(env_path)
api_key = os.getenv("GEMINI_API_KEY")
# C·∫•u h√¨nh API Key
genai.configure(api_key=api_key)
# Ch·ªçn m√¥ h√¨nh Gemini
model = genai.GenerativeModel("gemini-1.5-flash")


def get_latest_user_histories(user_id, limit=3):
    latest_histories = (
        History.objects
        .filter(user_id=user_id, complete=True)
        .select_related('test')
        .order_by('-id')[:limit]  # Gi·∫£ s·ª≠ c√≥ tr∆∞·ªùng completion_time
    )
    return latest_histories


def get_user_info_prompt_single(history, all_histories):
    """
    T·∫°o prompt ch·ª©a th√¥ng tin c·ªßa m·ªôt b√†i thi ri√™ng bi·ªát.
    Ph√¢n t√≠ch t·ª´ng ph·∫ßn c·ªßa b√†i thi v√† tr·∫£ v·ªÅ ph·∫£n h·ªìi t·ª´ AI.
    """
    # L·ªçc ra c√°c b√†i c√≥ c√πng t√™n ƒë·ªÅ thi
    same_test_histories = [h for h in all_histories if h.test.name == history.test.name]

    # S·∫Øp x·∫øp theo th·ªùi gian ho√†n th√†nh (ho·∫∑c id n·∫øu mu·ªën)
    same_test_histories.sort(key=lambda h: h.completion_time)

    # T√¨m ch·ªâ s·ªë l·∫ßn l√†m b√†i (tƒÉng t·ª´ 1)
    attempt_number = same_test_histories.index(history) + 1

    user_info = f"""
T√™n ƒë·ªÅ thi: {history.test.name} (L·∫ßn l√†m th·ª© {attempt_number})
Listening: {history.listening_score}
Reading: {history.reading_score}
T·ªïng ƒëi·ªÉm: {history.score}
ƒê√°p √°n ƒë√∫ng: {history.correct_answers}
T·ª∑ l·ªá ƒë√∫ng: {history.percentage_score}%
Th·ªùi gian ho√†n th√†nh: {history.completion_time} gi√¢y
Sai: {history.wrong_answers} | B·ªè qua: {history.unanswer_questions}
"""

    prompt = f"""
D∆∞·ªõi ƒë√¢y l√† th√¥ng tin b√†i thi TOEIC c·ªßa ng∆∞·ªùi d√πng:
{user_info}
H√£y ph√¢n t√≠ch k·∫øt qu·∫£ ƒëi·ªÉm s·ªë Listening v√† Reading trong b√†i thi n√†y v√† ƒë∆∞a ra l·ªùi khuy√™n ng·∫Øn g·ªçn, r√µ r√†ng:
- Ph·∫ßn n√†o c·∫ßn c·∫£i thi·ªán, Listening hay Reading?
"""

    print(f"[DEBUG] Prompt g·ª≠i ƒëi cho ƒë·ªÅ '{history.test.name}' - L·∫ßn {attempt_number}")
    response = model.generate_content(prompt)  # G·ªçi AI ƒë·ªÉ ph√¢n t√≠ch
    return response.text


def get_user_info_prompt_multi(user_id):
    """
    T·∫°o prompt cho t·∫•t c·∫£ c√°c b√†i thi c·ªßa ng∆∞·ªùi d√πng.
    Ph√¢n t√≠ch v√† nh·∫≠n ph·∫£n h·ªìi cho t·ª´ng b√†i thi ri√™ng bi·ªát.
    """
    histories = get_latest_user_histories(user_id, limit=3)  # L·∫•y t·∫•t c·∫£ l·ªãch s·ª≠ thi c·ªßa ng∆∞·ªùi d√πng
    if not histories:
        return "Kh√¥ng t√¨m th·∫•y l·ªãch s·ª≠ l√†m b√†i cho ng∆∞·ªùi d√πng n√†y."

    # Ph√¢n t√≠ch t·ª´ng b√†i thi v√† l·∫•y ph·∫£n h·ªìi cho m·ªói b√†i
    feedbacks = []
    for history in histories:
        feedback = get_user_info_prompt_single(history, histories)
        feedbacks.append({
            "test_name": history.test.name,
            "feedback": feedback
        })

    return feedbacks


def create_toeic_question_prompt(question_text, answers, audio=None, image=None):
    """
    T·∫°o prompt ph√¢n t√≠ch c√¢u h·ªèi TOEIC v√† ƒë∆∞a ra ƒë√°p √°n ƒë√∫ng.

    Parameters:
        question_text (str): N·ªôi dung c√¢u h·ªèi.
        answers (dict): Dictionary ch·ª©a c√°c ƒë√°p √°n.
        audio (list, optional): Danh s√°ch URL file √¢m thanh (n·∫øu c√≥).
        image (list, optional): Danh s√°ch URL h√¨nh ·∫£nh (n·∫øu c√≥).

    Returns:
        str: Ph√¢n t√≠ch t·ª´ AI v·ªÅ c√¢u h·ªèi TOEIC v√† ƒë√°p √°n ƒë√∫ng.
    """
    if not answers or not isinstance(answers, dict):
        raise ValueError("answers ph·∫£i l√† m·ªôt dictionary ch·ª©a ƒë√°p √°n theo d·∫°ng key-value.")

    formatted_answers = "\n".join([f"({key}) {value}" for key, value in answers.items()])
    audio_text = "\n".join(audio) if isinstance(audio, list) and audio else "Kh√¥ng c√≥"
    if isinstance(image, list):
        image_text = "\n".join(image)
    elif isinstance(image, str):
        image_text = image
    else:
        image_text = "Kh√¥ng c√≥"

    # G·∫Øn ti√™u ƒë·ªÅ r√µ r√†ng ƒë·ªÉ AI hi·ªÉu n·ªôi dung t·ª´ ·∫£nh
    image_text = f"N·ªôi dung tr√≠ch xu·∫•t t·ª´ h√¨nh ·∫£nh:\n{image_text}"

    toeic_question = f"""
    C√¢u h·ªèi:
    {question_text}
    {formatted_answers}

    Transcript: {audio_text}
    M√¥ t·∫£: {image_text}
    """

    prompt = f"""
    B·∫°n l√† m·ªôt chuy√™n gia TOEIC. D∆∞·ªõi ƒë√¢y l√† m·ªôt c√¢u h·ªèi trong b√†i thi TOEIC:
    {toeic_question}

    H√£y th·ª±c hi·ªán c√°c b∆∞·ªõc sau:

    1. Ph√¢n t√≠ch xem c√¢u h·ªèi n√†y thu·ªôc **k·ªπ nƒÉng n√†o** (Listening hay Reading).
    2. X√°c ƒë·ªãnh ch√≠nh x√°c c√¢u h·ªèi n√†y thu·ªôc **Part m·∫•y** trong ƒë·ªÅ thi TOEIC (Part 1 ƒë·∫øn Part 7).
    3. **Ch·ªçn ƒë√°p √°n ƒë√∫ng nh·∫•t** trong c√°c ƒë√°p √°n A, B, C, D.
    4. **Gi·∫£i th√≠ch chi ti·∫øt l√Ω do ch·ªçn ƒë√°p √°n ƒë√≥** v√† t·∫°i sao c√°c ƒë√°p √°n c√≤n l·∫°i kh√¥ng ph√π h·ª£p.

    Tr·∫£ l·ªùi r√µ r√†ng, ng·∫Øn g·ªçn nh∆∞ng s√∫c t√≠ch v√† d·ªÖ hi·ªÉu.
    """
    print("üß† Prompt g·ª≠i ƒë·∫øn AI:")
    print(prompt)
    response = model.generate_content(prompt)
    return response.text


def analyze_toeic_question(question_text, answers, audio=None, image=None):
    """
    Ph√¢n t√≠ch c√¢u h·ªèi TOEIC ƒë·ªÉ x√°c ƒë·ªãnh n√≥ thu·ªôc ph·∫ßn n√†o (Listening hay Reading) v√† Part n√†o (1-7).

    Parameters:
        question_text (str): N·ªôi dung c√¢u h·ªèi.
        answers (dict): Dictionary ch·ª©a c√°c ƒë√°p √°n theo d·∫°ng key-value, v√≠ d·ª•: {"A": "ƒê√°p √°n A", "B": "ƒê√°p √°n B", ...}.
        audio (list, optional): Danh s√°ch URL file √¢m thanh (n·∫øu c√≥).
        image (list, optional): Danh s√°ch URL h√¨nh ·∫£nh (n·∫øu c√≥).

    Returns:
        str: K·∫øt qu·∫£ ph√¢n t√≠ch t·ª´ AI.
    """
    # Ki·ªÉm tra answers ph·∫£i l√† dictionary
    if not answers or not isinstance(answers, dict):
        raise ValueError("answers ph·∫£i l√† m·ªôt dictionary ch·ª©a ƒë√°p √°n theo d·∫°ng key-value.")

    # ƒê·ªãnh d·∫°ng danh s√°ch ƒë√°p √°n t·ª´ dictionary
    formatted_answers = "\n".join([f"({key}) {value}" for key, value in answers.items()])

    # X·ª≠ l√Ω danh s√°ch audio v√† image, tr√°nh l·ªói khi kh√¥ng c√≥ d·ªØ li·ªáu
    audio_text = "\n".join(audio) if isinstance(audio, list) and audio else "None"
    if isinstance(image, list):
        image_text = "\n".join(image)
    elif isinstance(image, str):
        image_text = image
    else:
        image_text = "Kh√¥ng c√≥"

    # T·∫°o n·ªôi dung c√¢u h·ªèi ƒë·∫ßy ƒë·ªß (kh√¥ng c√≥ th·ªùi gian ph√¢n t√≠ch)
    toeic_question = f"""
    Question:
    {question_text}
    {formatted_answers}

    Audio: {audio_text}
    Image: {image_text}
    """

    # T·∫°o prompt cho AI
    prompt = f"""
    D∆∞·ªõi ƒë√¢y l√† m·ªôt c√¢u h·ªèi trong b√†i thi TOEIC:
    {toeic_question}
    H√£y ph√¢n t√≠ch c√¢u h·ªèi n√†y thu·ªôc ph·∫ßn n√†o c·ªßa b√†i thi TOEIC (Listening hay Reading),  
    v√† x√°c ƒë·ªãnh n√≥ thu·ªôc Part n√†o (Part 1, 2, 3, 4, 5, 6 ho·∫∑c 7). Gi·∫£i th√≠ch l√Ω do t·∫°i sao.
    """

    # Gi·∫£ s·ª≠ r·∫±ng 'model' l√† ƒë·ªëi t∆∞·ª£ng AI model ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a to√†n c·ª•c

    response = model.generate_content(prompt)

    return response.text


# V√≠ d·ª• s·ª≠ d·ª•ng v·ªõi JSON object
# D·ªØ li·ªáu ƒë·∫ßu v√†o
question_text = "What are the speakers discussing?"
answers = {
    "A": "A business trip.",
    "B": "A budget proposal.",
    "C": "An upcoming conference.",
    "D": "A package delivery."
}
audio = "https://s4-media1.study4.com/media/tez_media/sound/eco_toeic_1000_test_2_32_34.mp3"
image = None
# "https://s4-media1.study4.com/media/gg_imgs/test/9a18decce4319016bc774c19922917c0c4ff4413.jpg"
# Fetch the image from the URL
# response = requests.get(image)
# img = Image.open(BytesIO(response.content))
# # Extract text from the image
# text_img = pytesseract.image_to_string(img)
# print("Extracted Text:")
# print(text_img)
# response = requests.get(audio)
# with open("audio.mp3", "wb") as f:
#     f.write(response.content)
#
# # Chuy·ªÉn mp3 sang wav
# audio = AudioSegment.from_mp3("audio.mp3")
# audio.export("audio.wav", format="wav")
#
# # Nh·∫≠n d·∫°ng gi·ªçng n√≥i
# r = sr.Recognizer()
# with sr.AudioFile("audio.wav") as source:
#     audio_data = r.record(source)
#     try:
#         transcript = r.recognize_google(audio_data)
#         print("üéß N·ªôi dung tr√≠ch xu·∫•t t·ª´ audio:")
#         print(transcript)
#     except sr.UnknownValueError:
#         print("‚ö†Ô∏è Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c n·ªôi dung.")
#     except sr.RequestError as e:
#         print(f"‚ùå L·ªói k·∫øt n·ªëi ƒë·∫øn Google API: {e}")
# G·ªçi h√†m ƒë·ªÉ ph√¢n t√≠ch
analysis_result = create_toeic_question_prompt(question_text, answers, audio, image)

# In k·∫øt qu·∫£ ph√¢n t√≠ch
print(analysis_result)