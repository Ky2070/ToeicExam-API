from pathlib import Path
import google.generativeai as genai
import os
import json
from PIL import Image
import requests
from io import BytesIO
from pydub import AudioSegment
import speech_recognition as sr
import pytesseract
from dotenv import load_dotenv
import django

# Thi·∫øt l·∫≠p bi·∫øn m√¥i tr∆∞·ªùng tr∆∞·ªõc khi import models
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'EnglishApp.settings')  # Thay b·∫±ng t√™n project th·ª±c c·ªßa b·∫°n
django.setup()

from concurrent.futures import ThreadPoolExecutor
import time

executor = ThreadPoolExecutor(max_workers=10)  # t√πy b·∫°n ƒëi·ªÅu ch·ªânh s·ªë l∆∞·ª£ng thread

pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# ‚úÖ Th√™m ffmpeg v√†o PATH ƒë·ªÉ subprocess t√¨m th·∫•y
os.environ["PATH"] += os.pathsep + r"D:\tools-upgraders\ffmpeg-2025-04-14-git-3b2a9410ef-essentials_build\bin"

# üîß ƒê·∫∑t l·∫°i converter v√† ffprobe cho Pydub
AudioSegment.converter = r"D:\tools-upgraders\ffmpeg-2025-04-14-git-3b2a9410ef-essentials_build\bin\ffmpeg.exe"
AudioSegment.ffprobe = r"D:\tools-upgraders\ffmpeg-2025-04-14-git-3b2a9410ef-essentials_build\bin\ffprobe.exe"

print("‚úÖ Ki·ªÉm tra FFmpeg:", os.path.isfile(AudioSegment.converter))
print("‚úÖ Ki·ªÉm tra FFprobe:", os.path.isfile(AudioSegment.ffprobe))
# Load API Key t·ª´ file .env
env_path = Path(__file__).parent / '.env'
load_dotenv(env_path)
api_key = os.getenv("GEMINI_API_KEY")
# C·∫•u h√¨nh API Key
genai.configure(api_key=api_key)
# Ch·ªçn m√¥ h√¨nh Gemini
model = genai.GenerativeModel("gemini-1.5-flash")


def call_ai_sync(prompt):
    response = model.generate_content(
        prompt,
        stream=True,
        generation_config=genai.types.GenerationConfig(temperature=0.5),
        safety_settings={
            "HARASSMENT": "BLOCK_NONE",
            "HATE": "BLOCK_NONE",
            "SEXUAL": "BLOCK_NONE",
            "DANGEROUS": "BLOCK_NONE"
        }
    )

    return ''.join(chunk.text for chunk in response)


def get_user_info_prompt_multi(user_id, histories):
    """
    G·ªôp d·ªØ li·ªáu 3 b√†i thi g·∫ßn nh·∫•t c·ªßa ng∆∞·ªùi d√πng v√† t·∫°o m·ªôt ph·∫£n h·ªìi duy nh·∫•t t·ª´ AI.
    """
    if not histories:
        return "Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu b√†i thi."

    prompt_parts = []
    for i, history in enumerate(histories[::-1], start=1):  # ƒë·∫£o ng∆∞·ª£c ƒë·ªÉ t·ª´ c≈© -> m·ªõi
        same_test_histories = [h for h in histories if h.test.name == history.test.name]
        same_test_histories.sort(key=lambda h: h.completion_time)
        attempt_number = same_test_histories.index(history) + 1

        user_info = f"""
B√†i{i} [{history.test.name} - L·∫ßn {attempt_number}]: L={history.listening_score}, R={history.reading_score}, T={history.score}, ƒê√∫ng={history.percentage_score}%, Sai={history.wrong_answers}, B·ªè qua={history.unanswer_questions}
"""
        prompt_parts.append(user_info.strip())

    # Gh√©p to√†n b·ªô th√¥ng tin
    full_prompt = "\n\n".join(prompt_parts)

    # Prompt ch√≠nh g·ª≠i ƒë·∫øn AI
    final_prompt = f"""
B·∫°n l√† tr·ª£ l√Ω TOEIC chuy√™n ph√¢n t√≠ch k·∫øt qu·∫£ thi nhanh ch√≥ng. D∆∞·ªõi ƒë√¢y l√† 3 b√†i thi:

{full_prompt}

Ph√¢n t√≠ch nhanh v·ª´a ƒë·ªß √Ω, ph·∫£n h·ªìi ng·∫Øn g·ªçn: k·ªπ nƒÉng n√†o y·∫øu v√† g·ª£i √Ω c·∫£i thi·ªán (TOEIC 900)
"""

    # print("[DEBUG] Prompt g·ª≠i AI:")
    # print(final_prompt)

    # G·ªçi AI ƒë·ªÉ l·∫•y ph·∫£n h·ªìi
    start = time.time()
    result = executor.submit(call_ai_sync, final_prompt).result()
    end = time.time()
    print(f">>> Total: {end - start:.3f}s")  # th·ªùi gian ph·∫£n h·ªìi (ƒë√£ tr√¥i qua)
    return result


def create_toeic_question_prompt(question_text, answers, audio=None, image=None):
    """
    T·∫°o prompt ph√¢n t√≠ch c√¢u h·ªèi TOEIC v√† ƒë∆∞a ra ƒë√°p √°n ƒë√∫ng.

    Parameters:
        question_text (str): N·ªôi dung c√¢u h·ªèi.
        answers (dict): Dictionary ch·ª©a c√°c ƒë√°p √°n.
        audio (list, optional): Danh s√°ch URL file √¢m thanh (n·∫øu c√≥).
        image (list, optional): Danh s√°ch URL h√¨nh ·∫£nh (n·∫øu c√≥).

    Returns:
        str: Ph√¢n t√≠ch t·ª´ AI v·ªÅ c√¢u h·ªèi TOEIC v√† ƒë√°p √°n ƒë√∫ng.
    """
    if not answers or not isinstance(answers, dict):
        raise ValueError("answers ph·∫£i l√† m·ªôt dictionary ch·ª©a ƒë√°p √°n theo d·∫°ng key-value.")

    formatted_answers = "\n".join([f"({key}) {value}" for key, value in answers.items()])
    audio_text = "\n".join(audio) if isinstance(audio, list) and audio else "Kh√¥ng c√≥"
    if isinstance(image, list):
        image_text = "\n".join(image)
    elif isinstance(image, str):
        image_text = image
    else:
        image_text = "Kh√¥ng c√≥"

    # G·∫Øn ti√™u ƒë·ªÅ r√µ r√†ng ƒë·ªÉ AI hi·ªÉu n·ªôi dung t·ª´ ·∫£nh
    image_text = f"N·ªôi dung tr√≠ch xu·∫•t t·ª´ h√¨nh ·∫£nh:\n{image_text}"

    toeic_question = f"""
    C√¢u h·ªèi:
    {question_text}
    {formatted_answers}

    Transcript: {audio_text}
    M√¥ t·∫£: {image_text}
    """

    prompt = f"""
    B·∫°n l√† m·ªôt chuy√™n gia TOEIC. D∆∞·ªõi ƒë√¢y l√† m·ªôt c√¢u h·ªèi trong b√†i thi TOEIC:
    {toeic_question}

    H√£y th·ª±c hi·ªán c√°c b∆∞·ªõc sau:

    1. Ph√¢n t√≠ch xem c√¢u h·ªèi n√†y thu·ªôc **k·ªπ nƒÉng n√†o** (Listening hay Reading).
    2. X√°c ƒë·ªãnh ch√≠nh x√°c c√¢u h·ªèi n√†y thu·ªôc **Part m·∫•y** trong ƒë·ªÅ thi TOEIC (Part 1 ƒë·∫øn Part 7).
    3. **Ch·ªçn ƒë√°p √°n ƒë√∫ng nh·∫•t** trong c√°c ƒë√°p √°n A, B, C, D.
    4. **Gi·∫£i th√≠ch chi ti·∫øt l√Ω do ch·ªçn ƒë√°p √°n ƒë√≥** v√† t·∫°i sao c√°c ƒë√°p √°n c√≤n l·∫°i kh√¥ng ph√π h·ª£p.

    Tr·∫£ l·ªùi r√µ r√†ng, ng·∫Øn g·ªçn nh∆∞ng s√∫c t√≠ch v√† d·ªÖ hi·ªÉu.
    """
    response = model.generate_content(prompt)
    return response.text


def analyze_toeic_question(question_text, answers, audio=None, image=None):
    """
    Ph√¢n t√≠ch c√¢u h·ªèi TOEIC ƒë·ªÉ x√°c ƒë·ªãnh n√≥ thu·ªôc ph·∫ßn n√†o (Listening hay Reading) v√† Part n√†o (1-7).

    Parameters:
        question_text (str): N·ªôi dung c√¢u h·ªèi.
        answers (dict): Dictionary ch·ª©a c√°c ƒë√°p √°n theo d·∫°ng key-value, v√≠ d·ª•: {"A": "ƒê√°p √°n A", "B": "ƒê√°p √°n B", ...}.
        audio (list, optional): Danh s√°ch URL file √¢m thanh (n·∫øu c√≥).
        image (list, optional): Danh s√°ch URL h√¨nh ·∫£nh (n·∫øu c√≥).

    Returns:
        str: K·∫øt qu·∫£ ph√¢n t√≠ch t·ª´ AI.
    """
    # Ki·ªÉm tra answers ph·∫£i l√† dictionary
    if not answers or not isinstance(answers, dict):
        raise ValueError("answers ph·∫£i l√† m·ªôt dictionary ch·ª©a ƒë√°p √°n theo d·∫°ng key-value.")

    # ƒê·ªãnh d·∫°ng danh s√°ch ƒë√°p √°n t·ª´ dictionary
    formatted_answers = "\n".join([f"({key}) {value}" for key, value in answers.items()])

    # X·ª≠ l√Ω danh s√°ch audio v√† image, tr√°nh l·ªói khi kh√¥ng c√≥ d·ªØ li·ªáu
    audio_text = "\n".join(audio) if isinstance(audio, list) and audio else "None"
    if isinstance(image, list):
        image_text = "\n".join(image)
    elif isinstance(image, str):
        image_text = image
    else:
        image_text = "Kh√¥ng c√≥"

    # T·∫°o n·ªôi dung c√¢u h·ªèi ƒë·∫ßy ƒë·ªß (kh√¥ng c√≥ th·ªùi gian ph√¢n t√≠ch)
    toeic_question = f"""
    Question:
    {question_text}
    {formatted_answers}

    Audio: {audio_text}
    Image: {image_text}
    """

    # T·∫°o prompt cho AI
    prompt = f"""
    D∆∞·ªõi ƒë√¢y l√† m·ªôt c√¢u h·ªèi trong b√†i thi TOEIC:
    {toeic_question}
    H√£y ph√¢n t√≠ch c√¢u h·ªèi n√†y thu·ªôc ph·∫ßn n√†o c·ªßa b√†i thi TOEIC (Listening hay Reading),  
    v√† x√°c ƒë·ªãnh n√≥ thu·ªôc Part n√†o (Part 1, 2, 3, 4, 5, 6 ho·∫∑c 7). Gi·∫£i th√≠ch l√Ω do t·∫°i sao.
    """

    # Gi·∫£ s·ª≠ r·∫±ng 'model' l√† ƒë·ªëi t∆∞·ª£ng AI model ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a to√†n c·ª•c

    response = model.generate_content(prompt)

    return response.text


# V√≠ d·ª• s·ª≠ d·ª•ng v·ªõi JSON object
# D·ªØ li·ªáu ƒë·∫ßu v√†o
question_text = "What are the speakers discussing?"
answers = {
    "A": "A business trip.",
    "B": "A budget proposal.",
    "C": "An upcoming conference.",
    "D": "A package delivery."
}
audio = "https://s4-media1.study4.com/media/tez_media/sound/eco_toeic_1000_test_2_32_34.mp3"
image = None
# "https://s4-media1.study4.com/media/gg_imgs/test/9a18decce4319016bc774c19922917c0c4ff4413.jpg"
# Fetch the image from the URL
# response = requests.get(image)
# img = Image.open(BytesIO(response.content))
# # Extract text from the image
# text_img = pytesseract.image_to_string(img)
# print("Extracted Text:")
# print(text_img)
# response = requests.get(audio)
# with open("audio.mp3", "wb") as f:
#     f.write(response.content)
#
# # Chuy·ªÉn mp3 sang wav
# audio = AudioSegment.from_mp3("audio.mp3")
# audio.export("audio.wav", format="wav")
#
# # Nh·∫≠n d·∫°ng gi·ªçng n√≥i
# r = sr.Recognizer()
# with sr.AudioFile("audio.wav") as source:
#     audio_data = r.record(source)
#     try:
#         transcript = r.recognize_google(audio_data)
#         print("üéß N·ªôi dung tr√≠ch xu·∫•t t·ª´ audio:")
#         print(transcript)
#     except sr.UnknownValueError:
#         print("‚ö†Ô∏è Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c n·ªôi dung.")
#     except sr.RequestError as e:
#         print(f"‚ùå L·ªói k·∫øt n·ªëi ƒë·∫øn Google API: {e}")
# G·ªçi h√†m ƒë·ªÉ ph√¢n t√≠ch
# analysis_result = create_toeic_question_prompt(question_text, answers, audio, image)
#
# # In k·∫øt qu·∫£ ph√¢n t√≠ch
# print(analysis_result)